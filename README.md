# :fire: :fire:Awesome-LLMs-Mobile:fire::fire:

## :loudspeaker::loudspeaker::loudspeaker:This is a repo that covers the **on-device/edge/mobile** deployment of 2 types of llm

-  **large language models**
- **multi-modal large language model**.

## Related Work (papers):book:

### Survey

- Efficient large language models: A survey [[paper](https://arxiv.org/abs/2312.03863)] [[repo](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)]
- Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security [[paper](https://arxiv.org/pdf/2401.05459)] [[repo](https://github.com/MobileLLM/Personal_LLM_Agents_Survey)]

### LLM

- MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases (Arxiv 2024) [[paper](https://arxiv.org/abs/2402.14905)]
- A Performance Evaluation of a Quantized Large Language Model on Various Smartphones (Arxiv 2023) [[paper](https://arxiv.org/abs/2312.12472)]
- EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models (Arxiv 2023) [[paper](https://arxiv.org/pdf/2308.14352)]
- AutoDroid: LLM-powered Task Automation in Android (Arxiv 2023) [[paper](https://arxiv.org/pdf/2308.15272)] [[code](https://github.com/MobileLLM/AutoDroid)]
- Towards an On-device Agent for Text Rewriting (Arxiv 2023) [[paper](https://arxiv.org/abs/2308.11807)]
- LLM as a System Service on Mobile Devices (Arxiv 2024) [[paper](https://arxiv.org/pdf/2403.11805.pdf)] 
- Explore, Select, Derive, and Recall: Augmenting LLM
  with Human-like Memory for Mobile Task Automation (Arxiv 2023) [[paper](https://arxiv.org/abs/2312.03003)] 
- LLMCad: Fast and Scalable On-device Large Language Model Inference (Arxiv 2023) [[paper](https://arxiv.org/abs/2309.04255)]
- LLM in a flash: Efficient Large Language Model Inference with Limited Memory (Arxiv 2023) [[paper](https://arxiv.org/pdf/2312.11514.pdf)]
- PrivateLoRA For Efficient Privacy Preserving LLM (Arxiv 2023) [[paper](https://arxiv.org/abs/2311.14030)] [[code](https://github.com/alipay/private_llm)]
- Efficient Streaming Language Models with Attention Sinks (ICLR 2024) [[paper](https://arxiv.org/abs/2309.17453)] [[code](https://github.com/mit-han-lab/streaming-llm)]
- Efficient LLM inference solution on Intel GPU (Arxiv 2023) [[paper](https://arxiv.org/abs/2401.05391)]
- Accelerating LLM Inference with Staged Speculative Decoding (Arxiv 2023) [[paper](https://arxiv.org/abs/2308.04623)]
- Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile [[paper](https://arxiv.org/pdf/2310.01434)]

### MLLM

- MoE-LLaVA: Mixture of Experts for Large Vision-Language Models (Arxiv 2024) [[paper](https://arxiv.org/abs/2401.15947)] [[code](https://github.com/PKU-YuanGroup/MoE-LLaVA)]
- MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile Devices (Arxiv 2023) [[paper](https://arxiv.org/pdf/2312.16886)] [[code](https://github.com/Meituan-AutoML/MobileVLM)] 
- MobileVLM V2: Faster and Stronger Baseline for Vision Language Model (Arxiv 2024) [[paper](https://arxiv.org/pdf/2402.03766)] [[code](https://github.com/Meituan-AutoML/MobileVLM)]

## Related Work (project/code) :office:

### LLM

- llama.cpp [[code](https://github.com/ggerganov/llama.cpp)]
- alpaca.cpp [[code](https://github.com/antimatter15/alpaca.cpp/)]
- Phi2-mini-Chinese [[code](https://github.com/charent/Phi2-mini-Chinese)]
- Baby-llama2-Chinese [[code](https://github.com/DLLXW/baby-llama2-chinese)]
- MINI-LLM [[code](https://github.com/jiahe7ay/MINI_LLM)]
- ChatLM-mini-Chinese [[code](https://github.com/charent/ChatLM-mini-Chinese)]
- alpaca-electron [[code](https://github.com/ZiangWu-77/alpaca-electron)]
- FreedomGPT [[code](https://github.com/ohmplatform/FreedomGPT)]
- Lumos [[code](https://github.com/andrewnguonly/Lumos)]
- code-llama-for-vscode[[code](https://github.com/xNul/code-llama-for-vscode?tab=readme-ov-file)]
- AutoDroid [[code](https://github.com/MobileLLM/AutoDroid)]

### MLLM

- MiniCPM-2B [[code](https://github.com/OpenBMB/MiniCPM)]
- MobileVLM [[code](https://github.com/Meituan-AutoML/MobileVLM)]

### INFERENCE-TOOLKIT

- llama.cpp [[code](https://github.com/ggerganov/llama.cpp)]
- OpenVINO [[code](https://github.com/openvinotoolkit/openvino)]
- mlc-llm [[code](https://github.com/mlc-ai/mlc-llm)]
- BigDL [[code](https://github.com/ZiangWu-77/BigDL)]

### App
- lm-studio [[App](https://lmstudio.ai/)]
- mlc-llm.ai [[App](https://llm.mlc.ai/)]

### Web UI 
- gradio [[web](https://www.gradio.app/)]

### Desktop UI Framework
- electron [[web](https://www.electronjs.org/)]
- node.js [[web](https://nodejs.org/en)]
